{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nagaoka-ai-innovationhub/basics-of-image-recognition-with-cnn/blob/master/07_basics_of_convolutional_neural_networks.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みニューラルネットワークの基本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras`とFashon MNISTを使って、畳み込みニューラルネットワークを構築してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColabでのTensorFlow 2.xのインストール\n",
    "try:\n",
    "    # %tensorflow_version は Colab 上でのみ使えます\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# TensorFlowとtf.kerasのバージョン確認\n",
    "print(tf.version.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Fashon MNISTデータセットの読み込み\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラス名の定義\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 畳み込みニューラルネットワークモデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))   # 3x3の畳み込みカーネル(フィルタ) を32個、入力層は(28 x 28 x 1チャンネル)\n",
    "model.add(layers.MaxPooling2D((2, 2)))   # 2x2のMax Pooling\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))    # 3x3の畳み込みカーネル(フィルタ) を64個\n",
    "model.add(layers.MaxPooling2D((2, 2)))   # 2x2のMax Pooling\n",
    "\n",
    "model.add(layers.Flatten())     # 平滑化\n",
    "model.add(layers.Dense(128, activation='relu'))            # ノード数が128個の全結合層\n",
    "model.add(layers.Dense(10, activation='softmax'))     # 出力層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み層は`Conv2D`、プーリング層は`MaxPooling2D`を使用しています。\n",
    "以下の部分が画像の畳み込み処理を行う層になり、画像の特徴を自動的に抽出しています。\n",
    "\n",
    "```python\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "```\n",
    "\n",
    "画像データ入力の際は`(28*28)`に平滑化せずに、`(height, width, channels)`で与えてあげます。`channels`はカラー画像であればRGBの3チャンネルを使うことが多いですが、今回は白黒のグレースケールなので1チャンネルにしています。\n",
    "\n",
    "今回は畳み込み層1つ、プーリング層1つ、畳み込み層1つ、プーリング層1つの構成にしています。\n",
    "各層の出力は全て`(height, width, channels)`になります。\n",
    "畳込みカーネルの数だけ、チャンネルが増えます。また、プーリング層によって`(height, width)`は半分になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その後、畳み込み処理部分で得られた画像の特徴を元に、`Dense`層でニューラルネットワークと同じように分類をしています。\n",
    "\n",
    "```python\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "```\n",
    "\n",
    "`Dense`層へ値を渡す際には、パラメータの数分のベクトルで渡す必要があるので、その処理を`Flatten`で行なっています。\n",
    "その後の処理はニューラルネットワークと同じ内容です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの構造を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Flatten`層にて、`(5, 5, 64)`の出力は`(5*5*64)`に平滑化されていることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オプション: 図でモデル構造を表示（graphviz本体のインストールをした後で、pipでpydotplusとgraphvizのインストールが必要)\n",
    "#!pip install pydotplus\n",
    "#!pip install graphviz\n",
    "#from tensorflow.keras.utils import plot_model\n",
    "#\n",
    "#plot_model(model, to_file='basic_cnn_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コンパイルの内容はニューラルネットワークと同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',   # 損失関数は「categorical_crossentropy」\n",
    "    optimizer = 'rmsprop',  # オプティマイザは「rmsprop」\n",
    "    metrics = ['accuracy']  # 指標は「accuracy」（正答率）\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理\n",
    "\n",
    "データの前処理をしましょう。今回は以下のような処理になります。\n",
    "異なる点は、入力時に平滑化をする必要は無くなりましたが、チャネル数の部分を追加してあげる必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))  # 入力配列の構造にチャネル部分を追加\n",
    "train_images = train_images.astype('float32') / 255      # 値の範囲を[0,1]に正規化\n",
    "train_labels = to_categorical(train_labels)                        # ラベルをone-hot encoding\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))    # 入力配列の構造にチャネル部分を追加\n",
    "test_images = test_images.astype('float32') / 255        # 値の範囲を[0,1]に正規化\n",
    "test_labels = to_categorical(test_labels)                          # ラベルをone-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習\n",
    "\n",
    "畳み込み部分が追加されているため、パラメータ数が非常に多くなりました。\n",
    "そのため、学習には時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs: 全データを繰り返し学習する回数\n",
    "# batch_size: 1度に投入する入力データ数\n",
    "history = model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の推移をグラフ化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習の推移をグラフ化\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['accuracy']  # 学習データの正答率\n",
    "loss = history.history['loss']  # 学習データの損失\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Train Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, label='Train Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に上記コードをまとめておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColabでのTensorFlow 2.xのインストール\n",
    "try:\n",
    "    # %tensorflow_version は Colab 上でのみ使えます\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ライブラリの読み込み\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# TensorFlowとtf.kerasのバージョン確認\n",
    "print(tf.version.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "\n",
    "# Fashon MNISTデータセットの読み込み\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# クラス名の定義\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# モデルの構築\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))   # 3x3の畳み込みカーネル(フィルタ) を32個、入力層は(28 x 28 x 1チャンネル)\n",
    "model.add(layers.MaxPooling2D((2, 2)))   # 2x2のMax Pooling\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))    # 3x3の畳み込みカーネル(フィルタ) を64個\n",
    "model.add(layers.MaxPooling2D((2, 2)))   # 2x2のMax Pooling\n",
    "\n",
    "model.add(layers.Flatten())     # 平滑化\n",
    "model.add(layers.Dense(128, activation='relu'))            # ノード数が128個の全結合層\n",
    "model.add(layers.Dense(10, activation='softmax'))     # 出力層\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'rmsprop',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "# 学習データの前処理\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))  # 入力配列の構造にチャネル部分を追加\n",
    "train_images = train_images.astype('float32') / 255      # 値の範囲を[0,1]に正規化\n",
    "train_labels = to_categorical(train_labels)                        # ラベルをone-hot encoding\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))    # 入力配列の構造にチャネル部分を追加\n",
    "test_images = test_images.astype('float32') / 255        # 値の範囲を[0,1]に正規化\n",
    "test_labels = to_categorical(test_labels)                          # ラベルをone-hot encoding\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(train_images, train_labels, epochs = 5, batch_size = 128)\n",
    "\n",
    "# 学習の推移をグラフ化\n",
    "acc = history.history['accuracy']  # 学習データの正答率\n",
    "loss = history.history['loss']  # 学習データの損失\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Train Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, label='Train Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 学習済モデルの評価\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('test_acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 畳み込みニューラルネットワークは何を見ているか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、畳み込みニューラルネットワークについての理解を深めるために、学習済みのニューラルネットワークがどのような特徴をとらえているかを、隠れ層の出力（活性化マップ）を可視化することで見てみたいと思います。\n",
    "\n",
    "まず、学習済みモデルのフラット化の前の4層の出力を取得し、tf.keras のモデル activation_model を新たに作成します、。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers[:4]]\n",
    "\n",
    "# 既存モデルの入力と、上記で取得した各層の出力を出力とするモデルを構築\n",
    "activation_model = models.Model(inputs=model.inputs, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_images の最初の画像を入力として、推論（順方向処理）を実行します。　　\n",
    "test_images[0]とすると次元（階数）が1つ少ない (28, 28, 1)　の配列が得られるので、次元拡張によって形状を合わせていることに注意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "activations = activation_model.predict(np.expand_dims(test_images[0], 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activations は4層分あるので、最初の層の出力の形状をみてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(activations[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例として、インデックス3のフィルタの出力する特徴マップを、カラーマップを使って可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(activations[0][0, :, :, 3], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各層のパラメータは乱数によって初期化されるため、上記の特徴マップは訓練を実行するごとに異なることに注意。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記のプログラムにより、各層の特徴マップ全体を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各レイヤの名前を抽出\n",
    "layer_names = []\n",
    "for layer in model.layers[:4]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "# 1行に表示するイメージ数\n",
    "images_per_row = 16\n",
    "\n",
    "# レイヤごとに処理を繰り返す\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    # このレイヤの特徴マップの数を調べる\n",
    "    n_features = layer_activation.shape[-1]\n",
    "\n",
    "    # 特徴マップのサイズを取得（正方形を仮定している）\n",
    "    size = layer_activation.shape[1]\n",
    "\n",
    "    # 画像の行数を計算し画像を並べる0行列を生成\n",
    "    n_rows = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_rows, images_per_row * size))\n",
    "\n",
    "    # チャネルごとの特徴マップを取り出し行列に埋め込む\n",
    "    for row in range(n_rows):\n",
    "        for col in range(images_per_row):\n",
    "            channel_image = layer_activation[0, :, :, row * images_per_row + col]\n",
    "            # 特徴マップを平均0分散1に標準化\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            # 平均128標準偏差64に変換\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            # 0から255の範囲にクリッピングし符号なし8ビット整数化\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            # 所定の位置にイメージを埋め込む\n",
    "            display_grid[row * size : (row + 1) * size,\n",
    "                         col * size : (col + 1) * size] = channel_image\n",
    "\n",
    "    # 画像の表示\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
